{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001F6049D2F90> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F604AB0250> root_client=<openai.OpenAI object at 0x000001F604469350> root_async_client=<openai.AsyncOpenAI object at 0x000001F604AA7D10> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a subset of artificial intelligence that focuses on creating new content or data that is similar to existing datasets. Unlike traditional AI systems that are designed to recognize patterns and make decisions based on existing data, generative AI systems can produce novel outputs. These outputs can include text, images, music, and more.\\n\\nThe two most commonly discussed types of generative AI models are Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs). GANs consist of two neural networks, a generator and a discriminator, that are trained together to create data that is indistinguishable from real data. VAEs, on the other hand, encode input data into a compressed form and then decode it back, allowing the generation of new content by sampling from the encoded data space.\\n\\nGenerative AI has a wide range of applications, including:\\n\\n1. **Content Creation**: Automated creation of text, music, art, and other media.\\n2. **Design and Creativity**: Assisting with tasks like fashion design, product design, and architectural modeling.\\n3. **Data Augmentation**: Enhancing datasets by generating additional examples to improve the performance of other AI systems.\\n4. **Drug Discovery**: Creating new molecular structures for pharmaceuticals.\\n5. **Simulation**: Generating lifelike environments or scenarios for training purposes or entertainment.\\n\\nOverall, generative AI is a powerful tool that continues to evolve, providing significant opportunities as well as ethical and technical challenges.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 299, 'prompt_tokens': 13, 'total_tokens': 312, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-C4LZ1adKkC1ZWNUf861lMpAVuAbJ4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--8b286f56-ab5b-4f2b-8a7c-0e1f232068e3-0' usage_metadata={'input_tokens': 13, 'output_tokens': 299, 'total_tokens': 312, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a platform developed by LangChain designed to optimize and manage applications that utilize Language Models (LLMs) and AI agents. Released in July 2023, Langsmith provides an environment for the development, testing, debugging, deployment, and monitoring of LLM applications.\\n\\nThe platform simplifies the complex lifecycle management of LLM-based applications by offering features such as detailed tracing for debugging, version tracking, and performance dashboards to monitor application performance. It allows developers to iterate on their applications by providing insights into how models are performing, making it easier to identify issues and improve efficiency.\\n\\nLangsmith is particularly useful for teams building complex workflows that involve multiple AI models and agents, as it helps coordinate and streamline their interactions. This platform is integrated within the broader LangChain ecosystem and is aimed at enhancing the development experience for applications that depend heavily on language processing capabilities.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 171, 'prompt_tokens': 33, 'total_tokens': 204, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ff25b2783a', 'id': 'chatcmpl-C4LbOcFZbcrtMHTyRoByjqhLNXPKA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--0d81bcbe-18dc-4788-acc7-e5db620a51af-0' usage_metadata={'input_tokens': 33, 'output_tokens': 171, 'total_tokens': 204, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a suite of tools and services provided by Langchain designed to enhance the development, testing, and monitoring of language model applications. It offers capabilities for debugging and tracing to help developers effectively identify and resolve issues within their AI applications. Additionally, it provides evaluation tools that allow for systematic assessment and improvement of model performance. Langsmith aims to streamline the process of building robust and efficient language-based applications, offering tools for both local and hosted environments, with the hosted version referred to as LangSmith.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
